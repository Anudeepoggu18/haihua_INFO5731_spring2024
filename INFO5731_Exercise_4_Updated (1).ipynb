{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdRwkJBn70nX"
      },
      "source": [
        "# **INFO5731 In-class Exercise 4**\n",
        "\n",
        "**This exercise will provide a valuable learning experience in working with text data and extracting features using various topic modeling algorithms. Key concepts such as Latent Dirichlet Allocation (LDA), Latent Semantic Analysis (LSA), lda2vec, and BERTopic.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TU-pLW33lpcS"
      },
      "source": [
        "***Please use the text corpus you collected in your last in-class-exercise for this exercise. Perform the following tasks***.\n",
        "\n",
        "**Expectations**:\n",
        "*   Students are expected to complete the exercise during lecture period to meet the active participation criteria of the course.\n",
        "*   Use the provided .*ipynb* document to write your code & respond to the questions. Avoid generating a new file.\n",
        "*   Write complete answers and run all the cells before submission.\n",
        "*   Make sure the submission is \"clean\"; *i.e.*, no unnecessary code cells.\n",
        "*   Once finished, allow shared rights from top right corner (*see Canvas for details*).\n",
        "\n",
        "**Total points**: 40\n",
        "\n",
        "**Deadline**: This in-class exercise is due at the end of the day tomorrow, at 11:59 PM.\n",
        "\n",
        "**Late submissions will have a penalty of 10% of the marks for each day of late submission, and no requests will be answered. Manage your time accordingly.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARqm7u6B70ne"
      },
      "source": [
        "## Question 1 (10 Points)\n",
        "\n",
        "**Generate K topics by using LDA, the number of topics K should be decided by the coherence score, then summarize what are the topics.**\n",
        "\n",
        "You may refer the code here: https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAZj4PHB70nf",
        "outputId": "7de2d4a2-d1cd-4afe-8483-57d9c7b7f749"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The optimal number of topics is 3\n",
            "Topic 1: and of the its that with on inception visual masterpiece\n",
            "Topic 2: a and of is its with the performances mind sunshine\n",
            "Topic 3: of with and its the captivate cinema park effects storyline\n"
          ]
        }
      ],
      "source": [
        "# Write your code here\n",
        "import gensim\n",
        "from gensim import corpora\n",
        "from gensim.models import CoherenceModel\n",
        "\n",
        "# Prepare the text corpus\n",
        "texts = [\n",
        "    \"Inception is a mind-bending masterpiece that keeps viewers on the edge of their seats with its intricate plot and stunning visual effects.\",\n",
        "    \"The Godfather is a cinematic classic, with its gripping narrative, compelling characters, and iconic performances making it a timeless masterpiece.\",\n",
        "    \"Jurassic Park revolutionized the world of cinema with its groundbreaking special effects and thrilling storyline that continues to captivate audiences of all ages.\",\n",
        "    \"Eternal Sunshine of the Spotless Mind is a thought-provoking exploration of love and memory, with its inventive storytelling and heartfelt performances leaving a lasting impression\"\n",
        "]\n",
        "\n",
        "# Tokenize the texts\n",
        "tokenized_texts = [text.lower().split() for text in texts]\n",
        "\n",
        "# Create a dictionary from the tokenized texts\n",
        "dictionary = corpora.Dictionary(tokenized_texts)\n",
        "\n",
        "# Convert the tokenized texts into a bag-of-words representation\n",
        "corpus = [dictionary.doc2bow(text) for text in tokenized_texts]\n",
        "\n",
        "# Find the optimal number of topics using coherence score\n",
        "coherence_scores = {}\n",
        "for k in range(2, 8):\n",
        "    lda_model = gensim.models.ldamodel.LdaModel(\n",
        "        corpus=corpus,\n",
        "        id2word=dictionary,\n",
        "        num_topics=k,\n",
        "        random_state=100,\n",
        "        chunksize=100,\n",
        "        passes=10,\n",
        "        alpha='auto',\n",
        "        per_word_topics=True\n",
        "    )\n",
        "    coherence_model = CoherenceModel(\n",
        "        model=lda_model,\n",
        "        texts=tokenized_texts,\n",
        "        dictionary=dictionary,\n",
        "        coherence='c_v'\n",
        "    )\n",
        "    coherence_scores[k] = coherence_model.get_coherence()\n",
        "\n",
        "optimal_k = max(coherence_scores, key=coherence_scores.get)\n",
        "print(f\"The optimal number of topics is {optimal_k}\")\n",
        "\n",
        "# Train the LDA model with the optimal number of topics\n",
        "lda_model = gensim.models.ldamodel.LdaModel(\n",
        "    corpus=corpus,\n",
        "    id2word=dictionary,\n",
        "    num_topics=optimal_k,\n",
        "    random_state=100,\n",
        "    chunksize=100,\n",
        "    passes=10,\n",
        "    alpha='auto',\n",
        "    per_word_topics=True\n",
        ")\n",
        "\n",
        "# Summarize the topics\n",
        "topics = lda_model.show_topics(formatted=False)\n",
        "for i, topic in enumerate(topics):\n",
        "    print(f\"Topic {i+1}: {' '.join([w[0] for w in topic[1]])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEUjBE6C70nf"
      },
      "source": [
        "## Question 2 (10 Points)\n",
        "\n",
        "**Generate K topics by using LSA, the number of topics K should be decided by the coherence score, then summarize what are the topics.**\n",
        "\n",
        "You may refer the code here: https://www.datacamp.com/community/tutorials/discovering-hidden-topics-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoQX5s4O70nf",
        "outputId": "716822da-88f2-4da9-efdb-840afc5c05d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coherence Score:  0.6791577725415017\n",
            "Topic 1: ['of', 'and', 'a', 'with', 'its', 'the', 'is', 'performances', 'that', 'impression']\n",
            "Topic 2: ['a', 'of', 'that', 'revolutionized', 'Jurassic', 'all', 'world', 'effects', 'captivate', 'audiences']\n",
            "Topic 3: ['edge', 'viewers', 'stunning', 'seats', 'mind-bending', 'plot', 'on', 'visual', 'masterpiece', 'effects.']\n",
            "Topic 4: ['The', 'timeless', 'it', 'compelling', 'characters,', 'classic,', 'Godfather', 'narrative,', 'making', 'iconic']\n"
          ]
        }
      ],
      "source": [
        "# Write your code here\n",
        "from gensim.models import LsiModel\n",
        "from gensim.corpora import Dictionary\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "\n",
        "# Create dictionary\n",
        "texts_tokenized = [text.split() for text in texts]\n",
        "dictionary = Dictionary(texts_tokenized)\n",
        "\n",
        "# Create corpus\n",
        "corpus = [dictionary.doc2bow(text) for text in texts_tokenized]\n",
        "\n",
        "# Build LSA model\n",
        "num_topics = 4\n",
        "lsa_model = LsiModel(corpus, num_topics=num_topics, id2word=dictionary)\n",
        "\n",
        "# Compute coherence score\n",
        "coherence_model_lsa = CoherenceModel(model=lsa_model, texts=texts_tokenized, dictionary=dictionary, coherence='c_v')\n",
        "coherence_lsa = coherence_model_lsa.get_coherence()\n",
        "\n",
        "# Print coherence score\n",
        "print('Coherence Score: ', coherence_lsa)\n",
        "\n",
        "# Print topics\n",
        "topics = lsa_model.show_topics(formatted=False)\n",
        "for i, topic in enumerate(topics):\n",
        "    print('Topic {}: {}'.format(i+1, [word[0] for word in topic[1]]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oSK4soH70nf"
      },
      "source": [
        "## Question 3 (10 points):\n",
        "**Generate K topics by using lda2vec, the number of topics K should be decided by the coherence score, then summarize what are the topics.**\n",
        "\n",
        "You may refer the code here: https://nbviewer.org/github/cemoody/lda2vec/blob/master/examples/twenty_newsgroups/lda2vec/lda2vec.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CRuXfV570ng",
        "outputId": "f0afdcfd-7ca6-4c71-cde7-a3b65c51a940"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lda2vec in /usr/local/lib/python3.10/dist-packages (0.16.10)\n",
            "Topic 1: mind, visual, masterpiec, stun, bend, effect, edg, intric, viewer, incept\n",
            "Topic 2: perform, grip, classic, narr, godfath, compel, icon, charact, make, timeless\n",
            "Topic 3: continu, cinema, ag, world, revolution, storylin, thrill, jurass, special, effect\n",
            "Topic 4: audienc, captiv, groundbreak, park, effect, special, jurass, thrill, storylin, revolution\n",
            "Topic 5: seat, plot, keep, incept, viewer, masterpiec, intric, edg, effect, mind\n"
          ]
        }
      ],
      "source": [
        "# Write your code here\n",
        "!pip install lda2vec\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gensim\n",
        "from gensim.parsing.preprocessing import preprocess_string\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "texts = [\n",
        "    \"Inception is a mind-bending masterpiece that keeps viewers on the edge of their seats with its intricate plot and stunning visual effects.\",\n",
        "    \"The Godfather is a cinematic classic, with its gripping narrative, compelling characters, and iconic performances making it a timeless masterpiece.\",\n",
        "    \"Jurassic Park revolutionized the world of cinema with its groundbreaking special effects and thrilling storyline that continues to captivate audiences of all ages.\",\n",
        "    \"Eternal Sunshine of the Spotless Mind is a thought-provoking exploration of love and memory, with its inventive storytelling and heartfelt performances leaving a lasting impression\"\n",
        "]\n",
        "\n",
        "# Preprocess the text data\n",
        "processed_texts = [preprocess_string(text) for text in texts]\n",
        "\n",
        "# Create a dictionary and corpus\n",
        "dictionary = gensim.corpora.Dictionary(processed_texts)\n",
        "corpus = [dictionary.doc2bow(text) for text in processed_texts]\n",
        "\n",
        "# Train the LDA model\n",
        "vectorizer = CountVectorizer(stop_words=\"english\")\n",
        "doc_term_matrix = vectorizer.fit_transform(texts)\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "lda_model = gensim.models.LdaModel(corpus=corpus, id2word=dictionary, num_topics=5, passes=10)\n",
        "\n",
        "# Get the topics and their top words\n",
        "topics = lda_model.show_topics(num_topics=5, num_words=10, formatted=False)\n",
        "top_words_per_topic = []\n",
        "for topic in topics:\n",
        "    top_words = [word[0] for word in topic[1]]\n",
        "    top_words_per_topic.append(top_words)\n",
        "\n",
        "# Print the top words for each topic\n",
        "for i, top_words in enumerate(top_words_per_topic):\n",
        "    print(f\"Topic {i+1}: {', '.join(top_words)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nZGAOwl70ng"
      },
      "source": [
        "## Question 4 (10 points):\n",
        "**Generate K topics by using BERTopic, the number of topics K should be decided by the coherence score, then summarize what are the topics.**\n",
        "\n",
        "You may refer the code here: https://colab.research.google.com/drive/1FieRA9fLdkQEGDIMYl0I3MCjSUKVF8C-?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bertopic import BERTopic\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Sample text data\n",
        "texts = [\"Your text data goes here...\", \"Another document...\", \"...\"]\n",
        "\n",
        "# Preprocess the texts\n",
        "vectorizer = CountVectorizer(stop_words=\"english\")\n",
        "doc_term_matrix = vectorizer.fit_transform(texts)\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "# Create a BERTopic model and fit it to the document-term matrix\n",
        "model = BERTopic()\n",
        "topics, _ = model.fit_transform(doc_term_matrix)\n",
        "\n",
        "# Print the topics\n",
        "print(\"Number of topics:\", model.get_params()[\"n_components\"])\n",
        "print(\"\\nTopics:\")\n",
        "for topic_id in range(model.get_params()[\"n_components\"]):\n",
        "    topic_words = [feature_names[i] for i in model.get_topic(topic_id)]\n",
        "    print(f\"Topic {topic_id + 1}: {', '.join(topic_words)}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "7Ns6ScvHsI2m",
        "outputId": "21260950-52a0-40f3-a935-ffcecbb206a6"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Make sure that the iterable only contains strings.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-77fe8d053669>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Create a BERTopic model and fit it to the document-term matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBERTopic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mtopics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_term_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Print the topics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/bertopic/_bertopic.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, documents, embeddings, images, y)\u001b[0m\n\u001b[1;32m    371\u001b[0m         \"\"\"\n\u001b[1;32m    372\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdocuments\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m             \u001b[0mcheck_documents_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m             \u001b[0mcheck_embeddings_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/bertopic/_utils.py\u001b[0m in \u001b[0;36mcheck_documents_type\u001b[0;34m(documents)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIterable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Make sure that the iterable only contains strings.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Make sure that the documents variable is an iterable containing strings only.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Make sure that the iterable only contains strings."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wslk2SYHML8t"
      },
      "source": [
        "## **Question 3 (Alternative) - (10 points)**\n",
        "\n",
        "If you are unable to do the topic modeling using lda2vec, do the alternate question.\n",
        "\n",
        "Provide atleast 3 visualization for the topics generated by the BERTopic or LDA model. Explain each of the visualization in detail."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eKZHcPjpNEDx"
      },
      "outputs": [],
      "source": [
        "# Write your code here\n",
        "# Then Explain the visualization\n",
        "\n",
        "# Repeat for the other 2 visualizations as well."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d89ODUx3jjJV"
      },
      "source": [
        "## Extra Question (5 Points)\n",
        "\n",
        "**Compare the results generated by the four topic modeling algorithms, which one is better? You should explain the reasons in details.**\n",
        "\n",
        "**This question will compensate for any points deducted in this exercise. Maximum marks for the exercise is 40 points.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "OK34nZtojhmm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "99a26748-067a-4bfc-99c1-a4dda7d56439"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nLDA generated 3 topics, which is more than the other two algorithms. It identified some similar topics as LSA and LDA2Vec,\\nLSA generated 4 topics.\\nLDA2Vec generated 5 topics and identified some similar topics as LDA and LSA.\\nLDA and LDA2Vec generated more coherent and specific topics compared to LSA. LDA2Vec may have an advantage in identifying specific features and sentiments, while LDA seems to capture a more diverse range of topics.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# Write your code here\n",
        "'''\n",
        "LDA generated 3 topics, which is more than the other two algorithms. It identified some similar topics as LSA and LDA2Vec,\n",
        "LSA generated 4 topics.\n",
        "LDA2Vec generated 5 topics and identified some similar topics as LDA and LSA.\n",
        "LDA and LDA2Vec generated more coherent and specific topics compared to LSA. LDA2Vec may have an advantage in identifying specific features and sentiments, while LDA seems to capture a more diverse range of topics.'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEs-OoDEhTW4"
      },
      "source": [
        "# Mandatory Question"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUKC7suYhVl0"
      },
      "source": [
        "**Important: Reflective Feedback on this exercise**\n",
        "\n",
        "Please provide your thoughts and feedback on the exercises you completed in this assignment.\n",
        "\n",
        "Consider the following points in your response:\n",
        "\n",
        "**Learning Experience:** Describe your overall learning experience in working with text data and extracting features using various topic modeling algorithms. Did you understand these algorithms and did the implementations helped in grasping the nuances of feature extraction from text data.\n",
        "\n",
        "**Challenges Encountered:** Were there specific difficulties in completing this exercise?\n",
        "\n",
        "Relevance to Your Field of Study: How does this exercise relate to the field of NLP?\n",
        "\n",
        "**(Your submission will not be graded if this question is left unanswered)**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "CAq0DZWAhU9m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "1fdee3b6-1826-41bd-cad0-3aff69ee5625"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nPlease write you answer here:\\n\\nFor me all the topics are new and all these topics helped me in learning feature extraction from text data. I felt question 3, LDA2Vec and BERT topic challenging. \\n\\n\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# Your answer here (no code for this question, write down your answer as detail as possible for the above questions):\n",
        "\n",
        "'''\n",
        "Please write you answer here:\n",
        "\n",
        "For me all the topics are new and all these topics helped me in learning feature extraction from text data. I felt question 3, LDA2Vec and BERT topic challenging.\n",
        "\n",
        "\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xXTZe1E8pd0p"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}